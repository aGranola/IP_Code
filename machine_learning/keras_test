import numpy as np
from tensorflow import keras
from keras.models import Model
from keras.layers import Dense
import os
import matplotlib.pyplot as plt


import openvsp as vsp
import tensorflow as tf
import visualkeras

from ann_visualizer.visualize import ann_viz

cwd = os.getcwd()
print(cwd)

sampleSize = 100

#input data: L/D
#print(cwd + "/openvsp_api/sample_set/wingTest1/wingTest1_DegenGeom.polar")
inputData = []
for i in range(sampleSize):
    currentInputDataset = np.loadtxt(cwd + "/openvsp_api/sample_set/wingTest" + str(i+1) + "/wingTest" + str(i+1) + "_DegenGeom.polar", skiprows=1)
    currentInputSampleSet = []
    #read in colomn header to find value (look at read_csv using DictReader)
    currentInputSampleSet.append(currentInputDataset[11])
    inputData.append(currentInputSampleSet)
print(inputData)

#output data
outputData = []
for i in range(sampleSize):
    outputDatasetFilepath = cwd + "/openvsp_api/sample_set/wingTest" + str(i+1) + "/wingTest" + str(i+1) + ".vsp3"
    vsp.VSPRenew()
    vsp.ReadVSPFile(str(outputDatasetFilepath))
    geoms = vsp.FindGeoms()
    #print(geoms)
    wing = geoms[0]
    #add more parameters
    aspectRatioID = vsp.GetParm(wing, "Aspect", "XSec_1")
    aspectRatio = vsp.GetParmVal(aspectRatioID)
    print(aspectRatio)
    currentOutputSampleSet = []
    currentOutputSampleSet.append(aspectRatio)
    outputData.append(currentOutputSampleSet)
print(outputData)
inputData = np.array(inputData)
outputData = np.array(outputData)

def neural_network_training(sampleSize, 
                            inputData, 
                            outputData, 
                            valInput, 
                            valOutput, 
                            epochNo = 1000, 
                            plotLoss = True, 
                            visualiseModel = True
                            ):

    #split data into 3 groups so the model doesn't overfit
    trainSize = int(sampleSize*.6) #60% of the data is used for training
    valSize = int(sampleSize*.2) #20% is used to validate/improve the model as it is being trained
    testSize = int(sampleSize*.2) + 1 #20% is used to test the model with data nevr seen before

    trainInput, valInput, testInput = np.split(inputData, [trainSize, trainSize + valSize])
    trainOutput, valOutput, testOutput = np.split(outputData, [trainSize, trainSize + valSize])


    model = keras.Sequential()
    model.add(Dense(5, input_shape=(1,), activation='relu'))
    model.add(Dense(5, activation='relu'))
    model.add(Dense(1, activation='sigmoid'))

    model.compile(loss='mean_squared_error', optimizer='adam')

    logdir='logs'
    tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir)
    hist = model.fit(inputData, outputData, validation_data=(valInput, valOutput), epochs=epochNo, callbacks=[tensorboard_callback])

    if plotLoss == True:
        fig = plt.figure()
        plt.plot(hist.history['loss'], color='blue', label='loss')
        plt.plot(hist.history['val_loss'], color='pink', label='val_loss')
        fig.suptitle('Loss', fontsize=20)
        plt.legend(loc="upper left")
        plt.savefig("Loss Curve.png")
        plt.show()

    print(model.predict(testInput))
    print(testOutput)
    
    if visualiseModel == True:
        ann_viz(model, view = False)

#neural_network_training(sampleSize, inputData, outputData, valInput, valOutput)